{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these exercises we will use the [Coimbra Breast Cancer Dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra). This consists of 9 quantitative measures and 1 target value which indicates the presence or not of cancer (1=Healthy, 2=Cancerous).\n",
    "\n",
    "Please submit these completed exercises as a pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>70</td>\n",
       "      <td>2.707</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>8.8071</td>\n",
       "      <td>9.702400</td>\n",
       "      <td>7.99585</td>\n",
       "      <td>417.114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>20.690495</td>\n",
       "      <td>92</td>\n",
       "      <td>3.115</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>8.8438</td>\n",
       "      <td>5.429285</td>\n",
       "      <td>4.06405</td>\n",
       "      <td>468.786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>23.124670</td>\n",
       "      <td>91</td>\n",
       "      <td>4.498</td>\n",
       "      <td>1.009651</td>\n",
       "      <td>17.9393</td>\n",
       "      <td>22.432040</td>\n",
       "      <td>9.27715</td>\n",
       "      <td>554.697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>21.367521</td>\n",
       "      <td>77</td>\n",
       "      <td>3.226</td>\n",
       "      <td>0.612725</td>\n",
       "      <td>9.8827</td>\n",
       "      <td>7.169560</td>\n",
       "      <td>12.76600</td>\n",
       "      <td>928.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>92</td>\n",
       "      <td>3.549</td>\n",
       "      <td>0.805386</td>\n",
       "      <td>6.6994</td>\n",
       "      <td>4.819240</td>\n",
       "      <td>10.57635</td>\n",
       "      <td>773.920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age        BMI  Glucose  Insulin      HOMA   Leptin  Adiponectin  Resistin  \\\n",
       "0   48  23.500000       70    2.707  0.467409   8.8071     9.702400   7.99585   \n",
       "1   83  20.690495       92    3.115  0.706897   8.8438     5.429285   4.06405   \n",
       "2   82  23.124670       91    4.498  1.009651  17.9393    22.432040   9.27715   \n",
       "3   68  21.367521       77    3.226  0.612725   9.8827     7.169560  12.76600   \n",
       "4   86  21.111111       92    3.549  0.805386   6.6994     4.819240  10.57635   \n",
       "\n",
       "     MCP.1  Classification  \n",
       "0  417.114               1  \n",
       "1  468.786               1  \n",
       "2  554.697               1  \n",
       "3  928.220               1  \n",
       "4  773.920               1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coimbra = pd.read_csv('dataR2.csv')\n",
    "coimbra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57.301724</td>\n",
       "      <td>27.582111</td>\n",
       "      <td>97.793103</td>\n",
       "      <td>10.012086</td>\n",
       "      <td>2.694988</td>\n",
       "      <td>26.615080</td>\n",
       "      <td>10.180874</td>\n",
       "      <td>14.725966</td>\n",
       "      <td>534.647000</td>\n",
       "      <td>1.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.112766</td>\n",
       "      <td>5.020136</td>\n",
       "      <td>22.525162</td>\n",
       "      <td>10.067768</td>\n",
       "      <td>3.642043</td>\n",
       "      <td>19.183294</td>\n",
       "      <td>6.843341</td>\n",
       "      <td>12.390646</td>\n",
       "      <td>345.912663</td>\n",
       "      <td>0.499475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.370000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2.432000</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>4.311000</td>\n",
       "      <td>1.656020</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>45.843000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>22.973205</td>\n",
       "      <td>85.750000</td>\n",
       "      <td>4.359250</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>12.313675</td>\n",
       "      <td>5.474283</td>\n",
       "      <td>6.881763</td>\n",
       "      <td>269.978250</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>27.662416</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>5.924500</td>\n",
       "      <td>1.380939</td>\n",
       "      <td>20.271000</td>\n",
       "      <td>8.352692</td>\n",
       "      <td>10.827740</td>\n",
       "      <td>471.322500</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>31.241442</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>11.189250</td>\n",
       "      <td>2.857787</td>\n",
       "      <td>37.378300</td>\n",
       "      <td>11.815970</td>\n",
       "      <td>17.755207</td>\n",
       "      <td>700.085000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>38.578759</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>58.460000</td>\n",
       "      <td>25.050342</td>\n",
       "      <td>90.280000</td>\n",
       "      <td>38.040000</td>\n",
       "      <td>82.100000</td>\n",
       "      <td>1698.440000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age         BMI     Glucose     Insulin        HOMA      Leptin  \\\n",
       "count  116.000000  116.000000  116.000000  116.000000  116.000000  116.000000   \n",
       "mean    57.301724   27.582111   97.793103   10.012086    2.694988   26.615080   \n",
       "std     16.112766    5.020136   22.525162   10.067768    3.642043   19.183294   \n",
       "min     24.000000   18.370000   60.000000    2.432000    0.467409    4.311000   \n",
       "25%     45.000000   22.973205   85.750000    4.359250    0.917966   12.313675   \n",
       "50%     56.000000   27.662416   92.000000    5.924500    1.380939   20.271000   \n",
       "75%     71.000000   31.241442  102.000000   11.189250    2.857787   37.378300   \n",
       "max     89.000000   38.578759  201.000000   58.460000   25.050342   90.280000   \n",
       "\n",
       "       Adiponectin    Resistin        MCP.1  Classification  \n",
       "count   116.000000  116.000000   116.000000      116.000000  \n",
       "mean     10.180874   14.725966   534.647000        1.551724  \n",
       "std       6.843341   12.390646   345.912663        0.499475  \n",
       "min       1.656020    3.210000    45.843000        1.000000  \n",
       "25%       5.474283    6.881763   269.978250        1.000000  \n",
       "50%       8.352692   10.827740   471.322500        2.000000  \n",
       "75%      11.815970   17.755207   700.085000        2.000000  \n",
       "max      38.040000   82.100000  1698.440000        2.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coimbra.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values, and drop any rows which have missing values. Create a feature and target dataframe and split these into testing and training sets. (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coimbra.isnull().values.any()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = coimbra.drop(['Classification'], axis = 1) # drop the target variable for the features\n",
    "y = coimbra['Classification'] # create a target dataframe\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple Random Forest Classification as a baseline model, and calculate the accuracy for this model. (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.542\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# instantatiate the RFC with 200 ensemble members\n",
    "rfc = RandomForestClassifier(n_estimators=200).fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)  # calculate the predicted values\n",
    "# print the accuracy of the RFC\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a AdaBoost model with a Decision Stump and a learning rate of 1, and calculate the accuracy of this model. (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                            n_estimators=200, learning_rate=.1)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_pred = ada_clf.predict(X_test)  # calculate the predicted values\n",
    "# print the accuracy of the classifier\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same learning rate, find the optimal number of estimators. Just use the testing and training sets to calculate this, don't use cross-validation. (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.542]\n",
      "[0.625]\n",
      "[0.542]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.583]\n",
      "[0.625]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.625]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.583]\n",
      "[0.625]\n",
      "[0.583]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.625]\n",
      "[0.583]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.667]\n",
      "[0.625]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.625]\n",
      "[0.667]\n",
      "[0.625]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.625]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.625]\n",
      "[0.667]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.667]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.583]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.625]\n",
      "[0.583]\n",
      "[0.625]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n",
      "[0.583]\n"
     ]
    }
   ],
   "source": [
    "for n_est in range(1,201):\n",
    "    box=[]\n",
    "    ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                            n_estimators=n_est, learning_rate=.1)\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    y_pred = ada_clf.predict(X_test)  # calculate the predicted values\n",
    "# print the accuracy of the classifier\n",
    "    box.append(np.round(accuracy_score(y_test, y_pred),3))\n",
    "    print(box)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nests = np.arange(1,201,1)\n",
    "results=np.zeros(len(nests))\n",
    "for j in range(len(nests)):\n",
    "    ada_clf =AdaBoostClassifier(n_estimators = nests[j],learning_rate=1)\n",
    "    ada_clf.fit(X_train,y_train)\n",
    "    y_pred=ada_clf.predict(X_test)\n",
    "    results[j]=accuracy_score(y_test,y_pred)\n",
    "results_df=pd.DataFrame(results,columns=['accuracy(learning_rate=1)'],index=nests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54166667, 0.625     , 0.5       , 0.54166667, 0.54166667,\n",
       "       0.66666667, 0.66666667, 0.75      , 0.70833333, 0.70833333,\n",
       "       0.66666667, 0.66666667, 0.625     , 0.66666667, 0.625     ,\n",
       "       0.54166667, 0.625     , 0.58333333, 0.58333333, 0.625     ,\n",
       "       0.66666667, 0.70833333, 0.75      , 0.75      , 0.70833333,\n",
       "       0.66666667, 0.70833333, 0.70833333, 0.70833333, 0.70833333,\n",
       "       0.70833333, 0.70833333, 0.66666667, 0.70833333, 0.625     ,\n",
       "       0.625     , 0.58333333, 0.625     , 0.66666667, 0.66666667,\n",
       "       0.625     , 0.58333333, 0.58333333, 0.625     , 0.66666667,\n",
       "       0.66666667, 0.66666667, 0.66666667, 0.70833333, 0.66666667,\n",
       "       0.70833333, 0.70833333, 0.70833333, 0.70833333, 0.70833333,\n",
       "       0.70833333, 0.66666667, 0.70833333, 0.70833333, 0.70833333,\n",
       "       0.66666667, 0.70833333, 0.66666667, 0.70833333, 0.70833333,\n",
       "       0.70833333, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
       "       0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
       "       0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
       "       0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
       "       0.66666667, 0.66666667, 0.625     , 0.625     , 0.66666667,\n",
       "       0.625     , 0.625     , 0.66666667, 0.66666667, 0.625     ,\n",
       "       0.66666667, 0.66666667, 0.625     , 0.66666667, 0.66666667,\n",
       "       0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
       "       0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
       "       0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "       0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "       0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "       0.625     , 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "       0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "       0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "       0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "       0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "       0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "       0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "       0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.58333333,\n",
       "       0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "       0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "       0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "       0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "       0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "       0.54166667, 0.54166667, 0.54166667, 0.54166667, 0.54166667,\n",
       "       0.54166667, 0.58333333, 0.58333333, 0.58333333, 0.58333333])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_value = max(results)\n",
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_index = np.argmax(results, axis=0)\n",
    "max_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal estimators: 8(since index 7 means the eighth estimator is 8 that count from 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
